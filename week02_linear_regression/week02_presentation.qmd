---
title: "Linear Regression"
subtitle: "AERO 689: Introduction to Machine Learning for Aerospace Engineers"
author: "Dr. Raktim Bhattacharya"
institute: "Texas A&M University - Aerospace Engineering"
date: ""
format:
  revealjs:
    center: false
    width: 1920
    height: 1080
    slide-number: true
    transition: fade
    chalkboard:
      buttons: true
      chalk-width: 2
      boardmarker-width: 2
      chalk-effect: 0.01
      show: true
    preview-links: auto
    css: ../aero689-custom.css
    footer: "AERO 689 - Week 2: Linear Regression"
---

## Learning Objectives

- Apply linear regression to aerospace performance prediction
- Understand least squares method and gradient descent
- Implement drag coefficient prediction from wind tunnel data
- Validate models using aerospace-specific metrics

---

## The Fuel Crisis Challenge

### The $100 Million Question
**Scenario**: An airline operates 200 aircraft

- **Fuel cost**: $50M+ annually per aircraft type
- **Challenge**: Predict fuel consumption for flight planning
- **Current method**: Simplified performance charts
- **ML opportunity**: Precise models using real flight data

:::{.fragment}
### Real Impact

- 1% fuel savings = $100M+ industry-wide annually
- Better range predictions = route optimization
- Accurate payload calculations = safety + efficiency
:::

:::{.fragment}
> **Question for class**: *What factors affect aircraft fuel consumption?*
:::

---

## From Wind Tunnel to Flight - The Data Challenge 

### Traditional Approach: Empirical Models

**Parabolic Drag Polar**
$$
C_D = C_{D_0} + KC_L^2  
$$

- **Problem**: Assumes perfect conditions
- **Reality**: Real flights have weather, weight variations, engine degradation
- **Solution**: ML to learn from actual operational data

:::{.fragment}
### Available Data Sources
1. **Wind Tunnel Data**: Controlled, precise, limited conditions
2. **Flight Test Data**: Real conditions, expensive to collect
3. **Operational Data**: Massive scale, noisy, representative
:::

:::{.fragment}
### The Linear Regression Framework

- **Goal**: Predict drag coefficient (CD) from flight parameters
- **Input features**: Angle of attack ($\alpha$), Mach number (M), Reynolds number (Re)
- **Output**: Drag coefficient for performance calculations
:::

---

## Mathematical Foundation: The Linear Model

### General Form
For $n$ samples and $d$ features, the linear regression model is:

$$
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_d x_{id} + \epsilon_i
$$

where:

- $y_i$: response variable (e.g., drag coefficient)
- $x_{ij}$: $j$-th feature of $i$-th sample (e.g., Mach, $\alpha$, Re)
- $\beta_j$: regression coefficients (parameters to learn)
- $\epsilon_i$: error term (noise, unmodeled physics)

:::{.fragment}
### Vector Notation
$$
\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}
$$

where $\boldsymbol{X} \in \mathbb{R}^{n \times (d+1)}$ is the **design matrix** with augmented 1's for intercept
:::

---

## Matrix Formulation

### Design Matrix Structure
$$
\boldsymbol{X} = \begin{bmatrix}
1 & x_{11} & x_{12} & \cdots & x_{1d} \\
1 & x_{21} & x_{22} & \cdots & x_{2d} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{n1} & x_{n2} & \cdots & x_{nd}
\end{bmatrix}, \quad
\boldsymbol{\beta} = \begin{bmatrix}
\beta_0 \\ \beta_1 \\ \vdots \\ \beta_d
\end{bmatrix}, \quad
\boldsymbol{y} = \begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix}
$$

:::{.fragment}
### Aerospace Example: Drag Prediction

**Design matrix**:
$$
\boldsymbol{X} = \begin{bmatrix}
1 & \alpha_1 & M_1 & \text{Re}_1 & \alpha_1^2 & \alpha_1 M_1 & \cdots \\
1 & \alpha_2 & M_2 & \text{Re}_2 & \alpha_2^2 & \alpha_2 M_2 & \cdots \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
$$

**Parameters**: $\boldsymbol{\beta} = \begin{bmatrix} C_{D_0} & k_\alpha & k_M & k_{\text{Re}} & k_{\alpha^2} & k_{\alpha M} & \cdots \end{bmatrix}^T$

**Targets**: $\boldsymbol{y} = \begin{bmatrix} C_{D_1} & C_{D_2} & \cdots & C_{D_n} \end{bmatrix}^T$
:::

---

## Key Insight: What "Linear" Means

:::{.columns}
:::{.column width="50%"}
### "Linear Regression" = Linear in [Parameters]{.highlight}

**The model**: 
$$y = \beta_0 \phi_0(\boldsymbol{x}) + \beta_1 \phi_1(\boldsymbol{x}) + \cdots + \beta_d \phi_d(\boldsymbol{x})$$

**Where**:

- $\phi_j(\boldsymbol{x})$ are **basis functions** or **features** (can be nonlinear!)
  - Each $\phi_j: \mathbb{R}^p \to \mathbb{R}$ maps input features to a **scalar**
  - Examples: $\phi_0(\boldsymbol{x}) = 1$, $\phi_1(\boldsymbol{x}) = \alpha$, $\phi_2(\boldsymbol{x}) = \alpha^2$, $\phi_3(\boldsymbol{x}) = \sin(M)$
  - Output dimension matches $y$ (scalar for scalar regression, vector for multi-output)
- $\beta_j$ are **coefficients** (what we solve for)
  - Scalars for single-output regression (predicting one quantity like $C_D$)
  - Could be matrices for multi-output regression (predicting multiple quantities simultaneously)
  - **Note**: Design matrix $\boldsymbol{X}$ stays the same (n × (d+1)), only $\boldsymbol{\beta}$ and $\boldsymbol{y}$ change dimensions
- Model is **linear** in $\beta_j$, **not** in $\boldsymbol{x}$

:::{.fragment}
**Why it matters**:

- Linearity in $\boldsymbol{\beta}$ → closed-form solution exists
- Can model complex nonlinear phenomena
- Optimization remains [convex]{.highlight} (one global minimum)
:::
:::

:::{.column width="50%"}
:::{.fragment}
### Aerospace Example

**Drag coefficient model**:
$$
C_D = \beta_0 + \beta_1\alpha + \beta_2\alpha^2 + \beta_3 M^2 + \beta_4(\alpha M)
$$

**Analysis**:

- **Nonlinear function** of $\alpha$ and $M$ (parabola, interactions)
- **Linear combination** of terms: $\beta_0 \cdot 1 + \beta_1 \cdot \alpha + \beta_2 \cdot \alpha^2 + \cdots$
- **Linear in coefficients**: doubling $\beta_2$ doubles the $\alpha^2$ contribution

**Matrix form**: $\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta}^\ast$ where
$$
\boldsymbol{X} = \begin{bmatrix}
1 & \alpha_1 & \alpha_1^2 & M_1^2 & \alpha_1 M_1 \\
1 & \alpha_2 & \alpha_2^2 & M_2^2 & \alpha_2 M_2 \\
\vdots & \vdots & \vdots & \vdots & \vdots
\end{bmatrix}
$$
:::
:::
:::

---

## Real Data: Noisy Measurements

### Wind Tunnel Data Example

```{python}
#| echo: false
#| fig-align: center
#| fig-width: 12
#| fig-height: 7

import numpy as np
import matplotlib.pyplot as plt

# Set style
plt.style.use('dark_background')

# Generate realistic drag coefficient data
np.random.seed(42)
alpha = np.linspace(0, 12, 50)  # Angle of attack (degrees)

# True parabolic drag polar: CD = CD0 + k*CL^2, where CL ~ alpha (linear regime)
CD0 = 0.025  # Zero-lift drag
k = 0.05     # Induced drag factor
CL = 0.1 * alpha  # Simplified lift coefficient

# True relationship (parabolic)
CD_true = CD0 + k * CL**2

# Add realistic measurement noise (heteroscedastic - increases with alpha)
noise_std = 0.0008 + 0.0004 * alpha
noise = np.array([np.random.normal(0, std) for std in noise_std])
CD_measured = CD_true + noise

# Create plot
fig, ax = plt.subplots(figsize=(12, 7))

# Plot measured data points
ax.scatter(alpha, CD_measured, s=100, alpha=0.7, color='#3498db', 
           edgecolors='white', linewidth=1.5, label='Wind Tunnel Measurements', zorder=3)

# Plot true relationship
ax.plot(alpha, CD_true, 'r--', linewidth=3, label='True Relationship', zorder=2)

# Formatting
ax.set_xlabel(r'Angle of Attack, $\alpha$ (deg)', fontsize=20, fontweight='bold')
ax.set_ylabel(r'Drag Coefficient, $C_D$', fontsize=20, fontweight='bold')
ax.set_title('Real Wind Tunnel Data: Measurement Noise in Drag Polar', 
             fontsize=22, fontweight='bold', pad=20)
ax.legend(fontsize=18, loc='upper left', framealpha=0.9)
ax.grid(True, alpha=0.3, linestyle='--', linewidth=1)
ax.tick_params(labelsize=16)

# Add annotation showing noise
ax.annotate('Measurement noise increases\nwith angle of attack', 
            xy=(10, CD_measured[-5]), xytext=(7, 0.09),
            fontsize=16, color='yellow',
            arrowprops=dict(arrowstyle='->', color='yellow', lw=2),
            bbox=dict(boxstyle='round,pad=0.5', facecolor='black', alpha=0.7))

plt.tight_layout()
plt.show()
```

:::{.fragment}
**Key observations**:

- Data points scatter around true parabolic relationship
- Noise represents: sensor precision limits, flow unsteadiness, model simplification
- **This is why we need the error term** $\epsilon_i$ in our model!
:::

---

## The Optimization Problem

### Objective: Minimize Squared Error

**Residual Sum of Squares (RSS)**:
$$
\text{RSS}(\boldsymbol{\beta}) = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - \boldsymbol{x}_i^T\boldsymbol{\beta})^2
$$

:::{.fragment}
**Matrix form**:
$$
\text{RSS}(\boldsymbol{\beta}) = \|\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}\|^2 = (\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta})^T(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta})
$$
:::

:::{.fragment}
**Optimization goal**:
$$
\boldsymbol{\beta}^\ast = \arg\min_{\boldsymbol{\beta}} \text{RSS}(\boldsymbol{\beta})
$$
:::


:::{.fragment}
> **Physical interpretation**: Find aircraft model parameters that best match observed performance data
:::

---

## Derivation: Normal Equations

### Step 1: Expand the objective function
$$
\text{RSS}(\boldsymbol{\beta}) = \boldsymbol{y}^T\boldsymbol{y} - 2\boldsymbol{\beta}^T\boldsymbol{X}^T\boldsymbol{y} + \boldsymbol{\beta}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}
$$

:::{.fragment}
### Step 2: Take derivative with respect to $\boldsymbol{\beta}$
$$
\frac{\partial \text{RSS}}{\partial \boldsymbol{\beta}} = -2\boldsymbol{X}^T\boldsymbol{y} + 2\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}
$$
:::

:::{.fragment}
### Step 3: Set to zero and solve
$$
\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{X}^T\boldsymbol{y}
$$

**Normal Equations**
:::

:::{.fragment}
### Step 4: Solution (if $\boldsymbol{X}^T\boldsymbol{X}$ is invertible)
$$
\boldsymbol{\beta}^\ast = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}
$$
:::

---

## Geometric Interpretation: Understanding the Error

### What is the Error?

**Definition**: The error (residual) is the difference between observed data and our prediction:

$$
\boldsymbol{r} = \boldsymbol{y} - \hat{\boldsymbol{y}} = \boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}
$$

:::{.fragment}
**Our goal**: Minimize the **length** of this error vector:

$$
\min_{\boldsymbol{\beta}} \|\boldsymbol{r}\|^2 = \min_{\boldsymbol{\beta}} \|\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}\|^2
$$
:::

:::{.fragment}
### Key Geometric Insight

- **Column space col($\boldsymbol{X}$)**: Space spanned by basis functions (all possible predictions $\boldsymbol{X}\boldsymbol{\beta}$)
- **Data y**: Our actual observations (usually not in col($\boldsymbol{X}$) due to noise)
- **Question**: What is the **best** representation of $y$ in the feature space?

> **Answer:** Error is orthogonal to feature space  $\boldsymbol{X}^T\boldsymbol{r} = \boldsymbol{0}$ (error is orthogonal to all basis functions)

:::

---

## Why Projection Minimizes Error

### The Fundamental Geometric Principle

**Projection Theorem**: The shortest distance from a point to a subspace is achieved by the **perpendicular projection**.

```{python}
#| echo: false
#| fig-align: center
#| fig-width: 14
#| fig-height: 6

import numpy as np
import matplotlib.pyplot as plt

plt.style.use('dark_background')
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# LEFT PLOT: Simple geometric setup
ax1.set_xlim(-1, 5)
ax1.set_ylim(-1, 5)
ax1.set_aspect('equal')

# Column space as a line through origin
theta = np.radians(35)
col_dir = np.array([np.cos(theta), np.sin(theta)])
line_extent = np.linspace(-1, 5, 100)
line_points = np.outer(line_extent, col_dir)

# Draw column space
ax1.plot(line_points[:, 0], line_points[:, 1], 'c-', linewidth=8, 
        label='Column Space col($\\boldsymbol{X}$)', alpha=0.8, zorder=1)
ax1.fill_between(line_points[:, 0], line_points[:, 1] - 0.2, line_points[:, 1] + 0.2,
                color='cyan', alpha=0.2, zorder=0)

# Data point (not on the line)
y_point = np.array([3.5, 4.0])
ax1.scatter(*y_point, s=600, c='yellow', edgecolors='orange', 
           linewidths=4, marker='o', zorder=10, label='Data y')
ax1.text(y_point[0] + 0.3, y_point[1] + 0.2, 'y', fontsize=18, 
        color='yellow', fontweight='bold')

# Projection onto column space (perpendicular)
projection_coef = np.dot(y_point, col_dir)
y_hat = projection_coef * col_dir
ax1.scatter(*y_hat, s=600, c='lime', edgecolors='white', 
           linewidths=4, marker='o', zorder=10, label='Projection ŷ')
ax1.text(y_hat[0] - 0.5, y_hat[1] - 0.4, 'ŷ', fontsize=18, 
        color='lime', fontweight='bold')

# Residual (perpendicular to column space)
ax1.plot([y_point[0], y_hat[0]], [y_point[1], y_hat[1]], 
        'r-', linewidth=6, zorder=5, label='Residual r = y - ŷ')
ax1.arrow(y_hat[0], y_hat[1], (y_point[0] - y_hat[0]) * 0.7, 
         (y_point[1] - y_hat[1]) * 0.7,
         head_width=0.2, head_length=0.15, fc='red', ec='red', 
         linewidth=4, zorder=6)

# RIGHT ANGLE SYMBOL - make it very clear
square_size = 0.4
perp_dir = np.array([-col_dir[1], col_dir[0]])  # perpendicular to column space
corner = y_hat
square_v1 = square_size * col_dir
square_v2 = square_size * perp_dir
square_pts = [
    corner,
    corner + square_v1,
    corner + square_v1 + square_v2,
    corner + square_v2,
    corner
]
square_pts = np.array(square_pts)
ax1.plot(square_pts[:, 0], square_pts[:, 1], 'white', linewidth=3, zorder=8)
ax1.fill(square_pts[:, 0], square_pts[:, 1], color='white', alpha=0.3, zorder=7)
ax1.text(y_hat[0] + 0.6, y_hat[1] + 0.5, '90°', fontsize=16, 
        color='white', fontweight='bold',
        bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))

# Distance annotation
dist = np.linalg.norm(y_point - y_hat)
mid_point = (y_point + y_hat) / 2
ax1.text(mid_point[0] + 0.5, mid_point[1], f'||r|| = {dist:.2f}', 
        fontsize=14, color='red', fontweight='bold',
        bbox=dict(boxstyle='round', facecolor='black', alpha=0.8))

ax1.set_xlabel('Dimension 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('Dimension 2', fontsize=14, fontweight='bold')
ax1.set_title('Geometric View: Perpendicular Projection = Shortest Distance', 
             fontsize=15, fontweight='bold')
ax1.legend(fontsize=12, loc='upper left', framealpha=0.9)
ax1.grid(True, alpha=0.3, linewidth=1)

# RIGHT PLOT: Why perpendicular is optimal
ax2.set_xlim(-1, 5)
ax2.set_ylim(-1, 5)
ax2.set_aspect('equal')

# Draw column space again
ax2.plot(line_points[:, 0], line_points[:, 1], 'c-', linewidth=8, alpha=0.8, zorder=1)
ax2.fill_between(line_points[:, 0], line_points[:, 1] - 0.2, line_points[:, 1] + 0.2,
                color='cyan', alpha=0.2, zorder=0)

# Data point
ax2.scatter(*y_point, s=600, c='yellow', edgecolors='orange', 
           linewidths=4, marker='o', zorder=10)
ax2.text(y_point[0] + 0.3, y_point[1] + 0.2, 'y', fontsize=18, 
        color='yellow', fontweight='bold')

# Show several candidate points on the line
t_values = [0.6, 0.8, 1.0, 1.2, 1.4]
colors_candidates = ['red', 'orange', 'lime', 'orange', 'red']
for i, (t, color) in enumerate(zip(t_values, colors_candidates)):
    candidate = t * projection_coef * col_dir
    dist_candidate = np.linalg.norm(y_point - candidate)
    
    # Draw line to candidate
    if i == 2:  # Middle one is the optimal
        ax2.plot([y_point[0], candidate[0]], [y_point[1], candidate[1]], 
                color='lime', linewidth=5, zorder=5, linestyle='-', alpha=0.9)
        ax2.scatter(*candidate, s=500, c='lime', edgecolors='white', 
                   linewidths=4, marker='o', zorder=10)
        ax2.text(candidate[0] - 0.3, candidate[1] - 0.5, 
                f'ŷ\n{dist_candidate:.2f}✓', 
                fontsize=13, color='lime', fontweight='bold', ha='center',
                bbox=dict(boxstyle='round', facecolor='black', alpha=0.8))
    else:
        ax2.plot([y_point[0], candidate[0]], [y_point[1], candidate[1]], 
                color=color, linewidth=2, zorder=4, linestyle='--', alpha=0.5)
        ax2.scatter(*candidate, s=200, c=color, edgecolors='white', 
                   linewidths=2, marker='s', zorder=9, alpha=0.7)
        ax2.text(candidate[0], candidate[1] - 0.4, f'{dist_candidate:.2f}', 
                fontsize=11, color=color, ha='center',
                bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))

# Add perpendicular indicator at optimal point
y_hat_opt = projection_coef * col_dir
corner = y_hat_opt
square_pts = [
    corner,
    corner + square_size * col_dir,
    corner + square_size * col_dir + square_size * perp_dir,
    corner + square_size * perp_dir,
    corner
]
square_pts = np.array(square_pts)
ax2.plot(square_pts[:, 0], square_pts[:, 1], 'white', linewidth=3, zorder=8)

ax2.text(2.5, 0.5, 'Perpendicular gives\nSHORTEST distance!', 
        fontsize=14, color='lime', fontweight='bold', ha='center',
        bbox=dict(boxstyle='round', facecolor='black', alpha=0.9, 
                 edgecolor='lime', linewidth=3))

ax2.set_xlabel('Dimension 1', fontsize=14, fontweight='bold')
ax2.set_ylabel('Dimension 2', fontsize=14, fontweight='bold')
ax2.set_title('Why Perpendicular? Compare All Distances', 
             fontsize=15, fontweight='bold')
ax2.grid(True, alpha=0.3, linewidth=1)

plt.tight_layout()
plt.show()
```

:::{.fragment}
**Key Insight**: 

- The optimal $\hat{\boldsymbol{y}}$ is found by projecting $\boldsymbol{r}$ onto col($\boldsymbol{X}$) and setting it to zero
- This minimizes the error length: $||\boldsymbol{r}|| = ||\boldsymbol{y} - \hat{\boldsymbol{y}}||$ is smallest

**Mathematical statement**: $\boldsymbol{X}^T\boldsymbol{r} = \boldsymbol{X}^T(\boldsymbol{y} - \hat{\boldsymbol{y}}) = \boldsymbol{0}$
:::

---

## Deriving the Optimal Solution via Projection

### Step 1: State the Orthogonality Condition

**From geometry**: The error $\boldsymbol{r} = \boldsymbol{y} - \hat{\boldsymbol{y}}$ must be perpendicular to col($\boldsymbol{X}$)

$$
\boldsymbol{r} \perp \text{col}(\boldsymbol{X}) \quad \Longrightarrow \quad \boldsymbol{X}^T\boldsymbol{r} = \boldsymbol{0}
$$

:::{.fragment}
This is **the fundamental condition** for least squares optimality:

- $\boldsymbol{X}^T \boldsymbol{r}$ is a vector of dot products between $\boldsymbol{r}$ and each column of $\boldsymbol{X}$
- Each dot product = 0 means $\boldsymbol{r}$ is perpendicular to that column
- Zero vector means $\boldsymbol{r}$ is perpendicular to **all** columns (entire col($\boldsymbol{X}$))
:::

---

## Deriving the Optimal Solution via Projection

### Step 2: Express in Terms of β

Since optimal $\hat{\boldsymbol{y}}^\ast = \boldsymbol{X}\boldsymbol{\beta}^\ast$ and $\boldsymbol{r}^\ast = \boldsymbol{y} - \hat{\boldsymbol{y}}^\ast$, substitute into the orthogonality condition:

$$
\boldsymbol{X}^T\boldsymbol{r}^\ast = \boldsymbol{0}
$$

:::{.fragment}
$$
\boldsymbol{X}^T(\boldsymbol{y} - \hat{\boldsymbol{y}}^\ast) = \boldsymbol{0}
$$
:::

:::{.fragment}
$$
\boldsymbol{X}^T(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}^\ast) = \boldsymbol{0}
$$

Now we have an equation for $\boldsymbol{\beta}^\ast$ that we can solve!
:::

---

## Deriving the Optimal Solution via Projection

### Step 3: Derive the Normal Equations

Expand the orthogonality condition:

$$
\boldsymbol{X}^T(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}^\ast) = \boldsymbol{0}
$$

:::{.fragment}
$$
\boldsymbol{X}^T\boldsymbol{y} - \boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{0}
$$
:::

:::{.fragment}
$$
\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{X}^T\boldsymbol{y}
$$

These are the **Normal Equations** -- a linear system for $\boldsymbol{\beta}^\ast$.
:::

---

## Deriving the Optimal Solution via Projection

### Step 4: Solve for $\boldsymbol{\beta}^\ast$

Starting from the normal equations:

$$
\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{X}^T\boldsymbol{y}
$$

:::{.fragment}
Assuming $\boldsymbol{X}^T\boldsymbol{X}$ is invertible (columns of $\boldsymbol{X}$ are linearly independent):

$$
\boldsymbol{\beta}^\ast = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}
$$

This is the **closed-form solution** for ordinary least squares!
:::

:::{.fragment}
> **Key insight**: We derived this using **projection geometry** ($\boldsymbol{r}$ ⊥ col($\boldsymbol{X}$)) instead of **calculus** (∂J/∂β = 0). Both paths lead to the same solution!
:::

---

## Concrete Example: Verify Orthogonality

### Simple Linear Regression: y = β₀ + β₁x

```{python}
#| echo: false
#| fig-align: center
#| fig-width: 13
#| fig-height: 7

import numpy as np
import matplotlib.pyplot as plt

plt.style.use('dark_background')

# Generate data: 3 points for simplicity
np.random.seed(42)
x_vals = np.array([1, 2, 3])
# y_vals = np.array([2.1, 3.9, 6.2])
y_vals = np.array([2, 4, 9])

# Design matrix
X = np.column_stack([np.ones(3), x_vals])
print("X =", X)

# Solve
beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y_vals
y_hat = X @ beta_hat
residual = y_vals - y_hat

print(f"β̂ = {beta_hat}")
print(f"Residual = {residual}")

# Create figure
fig = plt.figure(figsize=(13, 7))

# LEFT: Show the fit
ax1 = fig.add_subplot(1, 2, 1)
ax1.scatter(x_vals, y_vals, s=300, c='yellow', edgecolors='orange', 
           linewidths=3, marker='o', zorder=5, label='Data points', alpha=0.9)
x_line = np.linspace(0.5, 3.5, 100)
y_line = beta_hat[0] + beta_hat[1] * x_line
ax1.plot(x_line, y_line, 'lime', linewidth=4, label=f'ŷ = {beta_hat[0]:.2f} + {beta_hat[1]:.2f}x')

# Draw residuals
for i in range(3):
    ax1.plot([x_vals[i], x_vals[i]], [y_vals[i], y_hat[i]], 
            'r--', linewidth=3, alpha=0.7)
    ax1.text(x_vals[i] + 0.1, (y_vals[i] + y_hat[i])/2, 
            f'r_{i+1}={residual[i]:.2f}',
            fontsize=11, color='red', fontweight='bold')

ax1.scatter(x_vals, y_hat, s=200, c='lime', edgecolors='white', 
           linewidths=2, marker='s', zorder=4, alpha=0.7)

ax1.set_xlabel('x', fontsize=14, fontweight='bold')
ax1.set_ylabel('y', fontsize=14, fontweight='bold')
ax1.set_title('Least Squares Fit: Observations vs Predictions', 
             fontsize=15, fontweight='bold')
ax1.legend(fontsize=12, loc='upper left')
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0.5, 3.5)

# RIGHT: Check orthogonality
ax2 = fig.add_subplot(1, 2, 2)

# Compute dot products
col1 = X[:, 0]  # [1, 1, 1]
col2 = X[:, 1]  # [1, 2, 3]

dot1 = np.dot(col1, residual)
dot2 = np.dot(col2, residual)

# Display columns and residual
ax2.text(0.5, 0.9, 'Column 1 (intercept):', fontsize=13, fontweight='bold', 
        transform=ax2.transAxes, color='cyan')
ax2.text(0.5, 0.83, f'  {col1}', fontsize=12, transform=ax2.transAxes, 
        color='cyan', family='monospace')

ax2.text(0.5, 0.72, 'Column 2 (x values):', fontsize=13, fontweight='bold', 
        transform=ax2.transAxes, color='dodgerblue')
ax2.text(0.5, 0.65, f'  {col2}', fontsize=12, transform=ax2.transAxes, 
        color='dodgerblue', family='monospace')

ax2.text(0.5, 0.54, 'Residual vector:', fontsize=13, fontweight='bold', 
        transform=ax2.transAxes, color='red')
ax2.text(0.5, 0.47, f'  {residual}', fontsize=12, transform=ax2.transAxes, 
        color='red', family='monospace')

# Dot products
ax2.text(0.5, 0.33, '—' * 40, fontsize=10, transform=ax2.transAxes, color='white')
ax2.text(0.5, 0.26, 'Orthogonality Check:', fontsize=14, fontweight='bold', 
        transform=ax2.transAxes, color='yellow')

ax2.text(0.5, 0.17, f'Column 1 · residual = {dot1:.6f} ≈ 0 ✓', 
        fontsize=13, transform=ax2.transAxes, color='lime', fontweight='bold',
        bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))

ax2.text(0.5, 0.08, f'Column 2 · residual = {dot2:.6f} ≈ 0 ✓', 
        fontsize=13, transform=ax2.transAxes, color='lime', fontweight='bold',
        bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))

ax2.axis('off')
ax2.set_title('Numerical Verification: Xᵀr ≈ 0', fontsize=15, fontweight='bold')

plt.tight_layout()
plt.show()
```

:::{.fragment}
**Confirmed**: Both dot products ≈ 0, proving the residual is perpendicular to **both** columns of $\boldsymbol{X}$!
:::

---

## The Projection Matrix

### Mathematical Form

From the normal equations $\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{X}^T\boldsymbol{y}$, we get:

$$
\boldsymbol{\beta}^\ast = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}
$$

:::{.fragment}
**Predicted values**:
$$
\hat{\boldsymbol{y}} = \boldsymbol{X}\boldsymbol{\beta}^\ast = \boldsymbol{X}(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y} = \boldsymbol{P}\boldsymbol{y}
$$

where $\boldsymbol{P} = \boldsymbol{X}(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T$ is the **projection matrix**
:::

:::{.fragment}
### Key Properties

1. **Idempotent**: $\boldsymbol{P}^2 = \boldsymbol{P}$ (projecting twice = projecting once)
2. **Symmetric**: $\boldsymbol{P}^T = \boldsymbol{P}$
3. **Projects onto $\text{col}(\boldsymbol{X})$**: $\boldsymbol{P}\boldsymbol{X} = \boldsymbol{X}$
4. **Residual matrix**: $\boldsymbol{I} - \boldsymbol{P}$ projects onto orthogonal complement
:::

:::{.fragment}
> **Aerospace insight**: The projection matrix $\boldsymbol{P}$ extracts the component of observed drag that can be explained by our aerodynamic features, leaving unexplained variance in the residuals
:::

---

## When Direct Solution Fails

### Challenges with $(\boldsymbol{X}^T\boldsymbol{X})^{-1}$

**Problem 1: Singular Matrix**

- Occurs when $n < d+1$ (more features than samples)
- Multicollinearity: highly correlated features

:::{.fragment}
**Problem 2: Computational Cost**

- Matrix inversion: $O(d^3)$ operations
- For large $d$ (high-dimensional features), impractical
:::

:::{.fragment}
**Problem 3: Numerical Stability**

- Ill-conditioned matrices (high condition number)
- Small perturbations → large changes in solution
:::

:::{.fragment}
### Solutions

1. **Regularization**: Ridge, Lasso 
2. **Gradient descent**: Iterative optimization
3. **QR decomposition**: Numerically stable direct method
4. **SVD**: Most stable, handles rank deficiency
:::

---

## Gradient Descent: Iterative Approach

### Algorithm

**Initialize**: $\boldsymbol{\beta}^{(0)}$ randomly or to zeros

**Iterate**: For $t = 0, 1, 2, \ldots$ until convergence:

$$
\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - \eta \nabla_{\boldsymbol{\beta}} \text{RSS}(\boldsymbol{\beta}^{(t)})
$$

where $\eta > 0$ is the **learning rate**

:::{.fragment}
### Gradient Computation
$$
\nabla_{\boldsymbol{\beta}} \text{RSS} = -2\boldsymbol{X}^T(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta})
$$

**Update rule**:
$$
\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} + 2\eta \boldsymbol{X}^T(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}^{(t)})
$$
:::

---

## Gradient Descent Variants

### Batch Gradient Descent
**Use all $n$ samples** in each iteration:
$$
\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - \eta \nabla_{\boldsymbol{\beta}} \text{RSS}(\boldsymbol{\beta}^{(t)})
$$

- ✓ Stable convergence
- ✗ Slow for large $n$

:::{.fragment}
### Stochastic Gradient Descent (SGD)
**Use one random sample** $i$ per iteration:
$$
\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} + 2\eta \boldsymbol{x}_i(y_i - \boldsymbol{x}_i^T\boldsymbol{\beta}^{(t)})
$$

- ✓ Fast updates, scales to large data
- ✗ Noisy, oscillates around minimum
:::

:::{.fragment}
### Mini-Batch Gradient Descent
**Use subset of $b$ samples** per iteration (typical: $b = 32, 64, 128$)

- ✓ Balance between speed and stability
- ✓ Vectorized operations (GPU-friendly)
:::

---

## Learning Rate Selection

### Critical Hyperparameter

$$
\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - \eta \nabla_{\boldsymbol{\beta}} \text{RSS}(\boldsymbol{\beta}^{(t)})
$$

:::{.columns}
:::{.column width="50%"}
**Too small** ($\eta \ll 1$):

- Slow convergence
- Many iterations needed
- Computationally expensive
:::

:::{.column width="50%"}
**Too large** ($\eta \gg 1$):

- Overshooting minimum
- Oscillation or divergence
- Never converges
:::
:::

:::{.fragment}
### Adaptive Learning Rates

1. **Learning rate decay**: $\eta_t = \frac{\eta_0}{1 + kt}$
2. **Momentum**: Use exponentially weighted moving average of gradients
3. **Adam**: Adaptive moment estimation (modern default)
4. **Line search**: Optimize $\eta$ at each iteration
:::

---

## Statistical Properties: Assumptions

### Classical Linear Regression Assumptions

:::{.fragment}
1. **Linearity**: True relationship is $\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$
:::

:::{.fragment}
2. **Independence**: Samples $(x_i, y_i)$ are i.i.d.
:::

:::{.fragment}
3. **Homoscedasticity**: Constant error variance $\text{Var}(\epsilon_i) = \sigma^2$
   - *Data collection context*: Measurement error should be consistent across operating range
   - *Example violation*: Wind tunnel balance accuracy degrades at low forces (high $\alpha$)
   - *Real-world impact*: Sensor noise may increase with altitude, velocity, or dynamic pressure
:::

:::{.fragment}
4. **Normality**: $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$
:::

:::{.fragment}
5. **No multicollinearity**: $\boldsymbol{X}^T\boldsymbol{X}$ is full rank
   - *Aerospace context*: Features should not be perfectly correlated
   - *Common violations*: 
     - Altitude and air density (directly related via ISA standard atmosphere)
     - Dynamic pressure and velocity ($q \propto V^2$ at fixed altitude)
     - Mach number and velocity at fixed altitude ($M = V/a$, where $a$ is constant)
     - Lift coefficient and angle of attack in linear regime (attached flow)
   - *Consequences*: Unstable coefficient estimates, inflated standard errors, unreliable predictions
   - *Detection*: Use VIF (Variance Inflation Factor) to identify problematic correlations
   - *Solutions*: Regularization (Ridge/Lasso), dimensionality reduction (PCA), or remove redundant features
:::

---

## Gauss-Markov: Implications for Practice

:::{.columns}

:::{.column width="50%"}

### Gauss-Markov Theorem

**Under assumptions 1-3**: The OLS estimator $\boldsymbol{\beta}^\ast = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}$ is:

- **BLUE**: Best Linear Unbiased Estimator
- Minimum variance among all unbiased linear estimators

**What Does BLUE Mean?**

:::{.fragment}
**Best**: Minimum variance (most precise estimates)

- Among all linear unbiased estimators, OLS has smallest variance
- No other linear unbiased method gives tighter confidence intervals
:::

:::{.fragment}
**Linear**: Estimator is linear function of $\boldsymbol{y}$

- Form: $\boldsymbol{\beta}^\ast = \boldsymbol{C}\boldsymbol{y}$ for some matrix $\boldsymbol{C}$
- OLS: $\boldsymbol{C} = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T$
:::

:::{.fragment}
**Unbiased**: $E[\boldsymbol{\beta}^\ast] = \boldsymbol{\beta}_\text{true}$

- On average, estimates equal true parameter values
- No systematic over/under-estimation
:::

:::

:::{.column width="50%"}

:::{.fragment}

### Aerospace Context

**Critical for certification**: 

- Flight envelope must be determined with minimal uncertainty
- BLUE property ensures tightest bounds on performance predictions
- Regulatory compliance requires unbiased, minimum-variance estimates

:::

:::

:::

---

## Statistical Inference: Understanding Uncertainty

### Why Do We Care About Uncertainty?

**Engineering Question**: After fitting $C_D = \beta_0 + \beta_1\alpha + \beta_2\alpha^2$, how confident are we in the coefficients?

:::{.fragment}
**Key Concepts**:

1. **Standard Error (SE)**: Measures uncertainty in each coefficient
   - Larger SE → less certain about coefficient value
   - Computed from residuals and design matrix

2. **Confidence Intervals**: Range of plausible values for each coefficient
   - Example: $\beta_1 = 0.105 \pm 0.008$ means true value likely between 0.097 and 0.113

3. **Statistical Significance**: Is a coefficient meaningfully different from zero?
   - **p-value < 0.05**: Strong evidence the feature matters
   - **p-value > 0.05**: Insufficient evidence (might just be noise)
:::

:::{.fragment}
**Practical Interpretation**:

Most ML libraries (scikit-learn, statsmodels) report these automatically. Focus on:

- Are confidence intervals narrow enough for your application?
- Which features have small p-values (statistically significant)?
:::

---

## Model Significance: Does Your Model Work?

### Overall Model Test

**Question**: Is the entire model better than just predicting the average value?

:::{.fragment}
**Simple Check - R² Statistic**:

$$
R^2 = 1 - \frac{\text{RSS}}{\text{TSS}} = \frac{\text{Variance Explained}}{\text{Total Variance}}
$$

- **R² ≈ 0**: Model is useless (no better than average)
- **R² ≈ 1**: Model explains almost all variance (excellent fit)
- **Rule of thumb for aerospace**: R² > 0.7 often acceptable for preliminary design
:::

:::{.fragment}
**Statistical Test - F-statistic**:

Tests if **any** features are useful (reported by most software)

- **Large F-value** (e.g., F > 10): Strong evidence model is useful
- **Small p-value** (p < 0.05): Model significantly better than baseline

**Bottom line**: Check that your model's p-value is small (<< 0.05) before using it!
:::

---

## Practical Example: Interpreting Regression Output

### Typical Software Output

```python
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm

# Fit model
model = sm.OLS(y, X).fit()
print(model.summary())
```

**What to look for**:

:::{.fragment}
1. **Overall Model**:
   - R²: Should be reasonably high (>0.7 for engineering)
   - F-statistic p-value: Should be < 0.05 (model is significant)

2. **Individual Coefficients**:
   - **Coefficient values**: Do they make physical sense?
   - **p-values** (P>|t|): Which features are significant?
     - p < 0.05: Feature is important, keep it
     - p > 0.05: Feature might not matter, consider removing
   - **Confidence intervals**: Are they narrow enough for your needs?
:::

:::{.fragment}
**Aerospace Example**:

If predicting $C_D$ from $\alpha$ and $M$, check that:

- $\alpha$ coefficient is positive (drag increases with angle of attack)
- Both p-values < 0.05 (both features matter)
- R² > 0.85 (good fit for aerodynamic data)
:::

---

## Model Evaluation: How Good is Our Fit?

### R-squared: The "Goodness of Fit" Metric

**Aerospace scenario**: You've modeled lift coefficient vs angle of attack. How well does your model explain the data?

:::{.fragment}
**R² tells you**: What fraction of the variance is explained by your model?

$$
R^2 = 1 - \frac{\text{Prediction errors}}{\text{Total variance}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}
$$

Think of it as: *How much better is my model than just using the average?*
:::

:::{.fragment}
**Example: Drag polar modeling**

- Without model: "Drag is around 0.025 on average" (just use mean)
- With model: $C_D = C_{D_0} + k C_L^2$ captures induced drag physics
- If $R^2 = 0.94$: Model explains 94% of drag variation
- Remaining 6%: Measurement noise, unmodeled effects (Reynolds number, surface roughness)
:::

---

## Model Evaluation: R-squared in Practice

### Interpreting R² Values

:::{.fragment}
**$R^2 = 0.99$** (Excellent fit)

- **Example**: Altitude vs atmospheric pressure
- Physics-based relationship is very strong
- Model captures nearly all variation
- Useful for precise predictions
:::

:::{.fragment}
**$R^2 = 0.75$** (Decent fit)

- **Example**: Fuel consumption vs flight parameters
- Multiple factors at play (weight, speed, wind, pilot technique)
- Model captures main trends but misses some complexity
- Good for general planning, not precise optimization
:::

:::{.fragment}
**$R^2 = 0.30$** (Weak fit)

- **Example**: Turbulence severity vs weather variables
- Many unmeasured factors influence outcome
- Model has some predictive power but high uncertainty
- Use with caution, gather more features
:::

---

## Model Evaluation: The R² Trap

### Problem: R² Always Increases with More Features!

**Wind tunnel experiment**: Modeling drag coefficient

:::{.fragment}
**Model 1**: $C_D = \beta_0 + \beta_1 M$ (just Mach number)

- $R^2 = 0.78$

**Model 2**: Add Reynolds number: $C_D = \beta_0 + \beta_1 M + \beta_2 Re$

- $R^2 = 0.85$ ✓ Better!

**Model 3**: Add random noise feature: $C_D = \beta_0 + \beta_1 M + \beta_2 Re + \beta_3(\text{noise})$

- $R^2 = 0.86$ ← Still increased! Even though noise has no meaning!
:::

:::{.fragment}
**The problem**: R² rewards complexity even when features add no real value

**Solution**: Use **Adjusted R²** which penalizes adding useless features

$$
R^2_{\text{adj}} = 1 - (1 - R^2)\frac{n-1}{n-d-1}
$$

Only increases if new feature improves fit more than expected by chance
:::

---

## Prediction Accuracy: RMSE

### Root Mean Squared Error: Speaking the Engineer's Language

**RMSE** = Average prediction error **in the same units as your measurement**

$$
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2}
$$

:::{.fragment}
**Aerospace Example 1: Range Prediction**

- Model predicts aircraft range for different payloads
- Actual range: 2,800 km, Predicted: 2,750 km → Error: 50 km
- After many flights: **RMSE = 85 km**
- **Interpretation**: "On average, range predictions are off by 85 km"
- **Decision**: Is ±85 km acceptable for mission planning? (Probably yes for long range, no for short hops)
:::

:::{.fragment}
**Aerospace Example 2: Landing Distance**

- Model predicts touchdown point on runway
- **RMSE = 45 m**
- **Interpretation**: Typical error is 45 meters from predicted spot
- **Decision**: With 2000m runway and 500m safety margin, this is acceptable
:::

---

## Prediction Accuracy: MAE vs RMSE

### When Do Outliers Matter?

**MAE (Mean Absolute Error)**: Treats all errors equally

$$
\text{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|
$$

**RMSE**: Penalizes large errors heavily (squaring effect)

:::{.fragment}
**Scenario: Predicting Stall Speed**

You have 20 test flights. 18 predictions are within 2 knots. 2 predictions are off by 10 knots.

- **MAE ≈ 3 knots**: Average error across all flights
- **RMSE ≈ 5 knots**: Higher due to those 2 large errors

**Which to use?**

- If you care equally about all predictions → **MAE**
- If large errors are dangerous (safety-critical) → **RMSE** (penalizes big misses)
:::

:::{.fragment}
**Aviation rule of thumb**:

- **Operational planning** (fuel, time estimates): MAE okay
- **Safety limits** (V-speeds, load factors): Use RMSE to be conservative
:::

---

## The Overfitting Problem

### Training vs Real-World Performance

**Wind tunnel scenario**: 50 data points of $C_L$ vs $\alpha$

:::{.fragment}
**Approach 1: Simple linear model**

- $C_L = \beta_0 + \beta_1 \alpha$
- Training RMSE: 0.08
- Fits main trend, some scatter
:::

:::{.fragment}
**Approach 2: Complex polynomial**

- $C_L = \beta_0 + \beta_1 \alpha + \beta_2 \alpha^2 + \cdots + \beta_{10} \alpha^{10}$
- Training RMSE: 0.02 (Much better!)
- Passes through almost every point!
:::

:::{.fragment}
**The test**: New wind tunnel run with 10 fresh measurements

- **Simple model**: Test RMSE = 0.09 (Similar to training)
- **Complex model**: Test RMSE = 0.31 (Much worse! 15x larger than training!)

**What happened?** Complex model **overfit** the noise in training data
:::

---

## Cross-Validation: Testing Without a Test Set

### The Problem with Single Train-Test Splits

**You have 100 flight test data points. How to evaluate your model?**

:::{.fragment}
**Option 1: Single 80-20 split** ❌

- Train on 80 flights, test on 20 flights
- Problem: Performance depends heavily on which 20 you held out
- Lucky split: high-performing model might just have easy test cases
- Unlucky split: good model might look bad with difficult test cases
:::

:::{.fragment}
**Option 2: Cross-validation** ✓

- **Everyone gets a chance to be test data**
- Split 100 flights into 10 groups of 10
- Train 10 different models, each time holding out a different group
- Average performance across all 10 test groups
- More reliable estimate of real-world performance
:::

---

## Cross-Validation: How It Works

### 5-Fold Cross-Validation Example

**Scenario**: 100 flight tests, modeling fuel consumption

:::{.fragment}
**Setup**:

1. Randomly divide 100 flights into 5 groups of 20 flights each
2. Groups: A, B, C, D, E
:::

:::{.fragment}
**The process**:

- **Round 1**: Train on {A,B,C,D}, test on E → Error₁
- **Round 2**: Train on {A,B,C,E}, test on D → Error₂
- **Round 3**: Train on {A,B,D,E}, test on C → Error₃
- **Round 4**: Train on {A,C,D,E}, test on B → Error₄
- **Round 5**: Train on {B,C,D,E}, test on A → Error₅

**Final estimate**: $\text{CV Error} = \frac{1}{5}(\text{Error}_1 + \cdots + \text{Error}_5)$
:::

:::{.fragment}
**Result**: Every single flight was used for testing exactly once!
:::

---

## Cross-Validation: Practical Considerations

### How Many Folds?

:::{.fragment}
**k = 5 or k = 10** (Most common in aerospace)

- **When**: 50-500 data points (typical wind tunnel campaigns, flight tests)
- **Why**: Good balance between computational cost and reliability
- **Each fold**: Still has enough data for training
- **Example**: 200 wind tunnel runs → 10 folds of 20 runs each
:::

:::{.fragment}
**k = 20 or Leave-One-Out** (Expensive but thorough)

- **When**: Very limited data (<50 points), expensive tests
- **Why**: Use maximum data for training
- **Cost**: Training many more models
- **Example**: 30 full-scale aircraft tests → Hold out 1 or 2 at a time
:::

:::{.fragment}
**Aerospace best practice**:

- **Research/development**: k=10 standard
- **Certification data** (expensive): Consider leave-one-out or k=n
- **Large datasets** (CFD, simulation): k=5 to save computation time
:::

---

## Model Evaluation Metrics: Complete Comparison

### Summary of All Error Metrics

| Metric | Formula | Units | Range | When to Use | Pros | Cons |
|--------|---------|-------|-------|-------------|------|------|
| **R²** | $1 - \frac{\text{RSS}}{\text{TSS}}$ | None | [0, 1] | Comparing models on same data | Intuitive (% variance explained) | Always increases with features |
| **Adj. R²** | $1 - (1-R^2)\frac{n-1}{n-d-1}$ | None | [-∞, 1] | Model selection (complexity) | Penalizes useless features | Can be negative |
| **MSE** | $\frac{1}{n}\sum(y_i-\hat{y}_i)^2$ | $y^2$ | [0, ∞) | Theoretical analysis | Easy to derive | Squared units, sensitive to outliers |
| **RMSE** | $\sqrt{\text{MSE}}$ | Same as $y$ | [0, ∞) | **General aviation use** | **Interpretable units** | Sensitive to outliers |
| **MAE** | $\frac{1}{n}\sum\|y_i-\hat{y}_i\|$ | Same as $y$ | [0, ∞) | Robust performance | Less sensitive to outliers | Harder to optimize |
| **MAPE** | $\frac{100}{n}\sum\frac{\|y_i-\hat{y}_i\|}{y_i}$ | % | [0, ∞) | Relative comparison | Scale-independent | Undefined if $y_i=0$ |

--- 

## Model Evaluation Metrics: Complete Comparison
### Aerospace recommendations

- **Design/certification**: Use **RMSE** (penalizes large errors for safety)
- **Operational planning**: Use **MAE** (typical errors for fuel/time estimates)  
- **Model comparison**: Use **Adj. R²** (accounts for model complexity)
- **Reporting results**: Report **multiple metrics** for complete picture

---

## Detailed Metric Analysis: R² and Adjusted R²

### R² (Coefficient of Determination)

$$
R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{\sum_{i=1}^n(y_i - \bar{y})^2} = 1 - \frac{\text{RSS}}{\text{TSS}} = \frac{\text{ESS}}{\text{TSS}}
$$

:::{.fragment}
**Physical interpretation**:

- **Numerator RSS**: Sum of squared residuals (what model can't explain)
- **Denominator TSS**: Total variance in data (if we only knew $\bar{y}$)
- **R²**: Fraction of variance **explained** by the model
- **1 - R²**: Fraction of variance **not explained** by the model
:::

:::{.fragment}
**Aerospace example - Lift slope prediction**:

- Wind tunnel data: 50 measurements of $C_L$ vs $\alpha$
- Simple model: $C_L = \beta_0 + \beta_1\alpha$
- TSS = 2.45 (total variance), RSS = 0.12 (residual variance)
- $R^2 = 1 - \frac{0.12}{2.45} = 0.951$ → Model explains **95.1%** of lift variation
- Remaining 4.9%: Measurement noise, 3D effects, tunnel wall interference
:::

---

## R² Limitations and Adjusted R²

### Why R² Can Be Misleading

:::{.fragment}
**Problem 1: Always increases with more features**

Adding ANY feature (even random noise) will increase R² or keep it the same, never decrease it.

**Example**:

- Model A: $C_D = \beta_0 + \beta_1\alpha$ → $R^2 = 0.82$
- Model B: $C_D = \beta_0 + \beta_1\alpha + \beta_2(\text{random noise})$ → $R^2 = 0.823$

Model B appears "better" but the extra feature is meaningless!
:::

:::{.fragment}
**Solution: Adjusted R²**

$$
R^2_{\text{adj}} = 1 - (1-R^2)\frac{n-1}{n-d-1} = 1 - \frac{\text{RSS}/(n-d-1)}{\text{TSS}/(n-1)}
$$

- **Penalizes** each additional feature by reducing degrees of freedom
- Only increases if new feature improves fit **more than expected by chance**
- Can **decrease** or even be **negative** if model is worse than baseline
:::

---

## Adjusted R²: Detailed Example

### Comparing Two Drag Models

**Dataset**: 60 wind tunnel runs at various $\alpha$ and $M$

:::{.fragment}
**Model 1 (Simple)**: $C_D = \beta_0 + \beta_1\alpha + \beta_2\alpha^2$

- $d = 2$ features, $n = 60$ data points
- RSS = 0.0045, TSS = 0.0520
- $R^2 = 1 - \frac{0.0045}{0.0520} = 0.913$
- $R^2_{\text{adj}} = 1 - (1-0.913)\frac{60-1}{60-2-1} = 1 - 0.087 \times \frac{59}{57} = 0.910$
:::

:::{.fragment}
**Model 2 (Complex)**: $C_D = \beta_0 + \beta_1\alpha + \beta_2\alpha^2 + \beta_3 M + \beta_4 M^2 + \beta_5\alpha M$

- $d = 5$ features, $n = 60$ data points  
- RSS = 0.0042, TSS = 0.0520
- $R^2 = 1 - \frac{0.0042}{0.0520} = 0.919$ → Slightly higher!
- $R^2_{\text{adj}} = 1 - (1-0.919)\frac{60-1}{60-5-1} = 1 - 0.081 \times \frac{59}{54} = 0.911$
:::

:::{.fragment}
**Decision**: Model 2 has slightly higher Adj. R² (0.911 vs 0.910), suggesting the Mach number terms add marginal value. But the improvement is small -- consider Model 1 for simplicity unless transonic effects are critical.
:::

---

## Detailed Metric Analysis: MSE and RMSE

### Mean Squared Error (MSE)

$$
\text{MSE} = \frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2 = \frac{\text{RSS}}{n}
$$

:::{.fragment}
**Properties**:

- **Always positive** (squared errors)
- **Penalizes large errors heavily** (quadratic penalty)
- **Units**: Squared units of response variable
- **Optimization**: Differentiable, easy to minimize (used in least squares)
- **Statistical connection**: Unbiased estimator of $\sigma^2$ when using $n-d-1$ denominator
:::

:::{.fragment}
### Root Mean Squared Error (RMSE)

$$
\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2}
$$

**Why take the square root?**

- Returns to **original units** of the response
- Makes interpretation intuitive: "Average prediction error in practical units"
- Comparable to standard deviation
:::

---

## RMSE: Aerospace Applications

### Example 1: Fuel Burn Prediction

**Model** - Predict fuel consumption (kg) for commercial flights

**Results on test data**:

- Actual fuel: [12,500, 14,200, 13,800, 15,100, 12,900] kg
- Predicted: [12,300, 14,500, 13,700, 15,000, 13,200] kg
- Errors: [200, -300, 100, 100, -300] kg
- MSE = $\frac{1}{5}(200^2 + 300^2 + 100^2 + 100^2 + 300^2) = \frac{230000}{5} = 46000$ kg²
- **RMSE = 214 kg**

:::{.fragment}
**Engineering interpretation**:

- "Fuel predictions are typically off by ±214 kg"
- For a flight requiring ~13,500 kg, error is ~1.6%
- **Decision**: Acceptable for operational planning with safety margins
:::

---

## RMSE: Aerospace Applications

### Example 2: Takeoff Distance Prediction

**Model** - Predict takeoff roll distance (m) given weight, temperature, pressure altitude

- **RMSE = 35 m** on validation set

**Safety assessment**:

- Runway length: 2,400 m
- Predicted takeoff distance: 1,650 m
- With RMSE = 35 m, roughly 95% of predictions within ±70 m
- Safety margin: 2,400 - 1,650 - 70 = 680 m ✓ Acceptable


---

## Detailed Metric Analysis: MAE

### Mean Absolute Error

$$
\text{MAE} = \frac{1}{n}\sum_{i=1}^n|y_i - \hat{y}_i|
$$

:::{.fragment}
**Properties**:

- **Linear penalty**: All errors treated equally (no squaring)
- **Robust to outliers**: Large errors don't dominate as in RMSE
- **Units**: Same as response variable (like RMSE)
- **Optimization**: Less smooth (absolute value not differentiable at 0)
:::

---

## MAE vs RMSE: Side-by-Side Comparison

### Same Dataset, Different Stories

**Scenario**: Predicting landing rollout distance (10 test landings)

| Landing | Actual (m) | Predicted (m) | Error (m) | Squared Error |
|---------|------------|---------------|-----------|---------------|
| 1 | 450 | 445 | 5 | 25 |
| 2 | 430 | 435 | -5 | 25 |
| 3 | 460 | 455 | 5 | 25 |
| 4 | 440 | 448 | -8 | 64 |
| 5 | 455 | 450 | 5 | 25 |
| 6 | 445 | 442 | 3 | 9 |
| 7 | 435 | 438 | -3 | 9 |
| 8 | 470 | 460 | 10 | 100 |
| 9 | 442 | 445 | -3 | 9 |
| 10 | 450 | 500 | **-50** | **2500** |

:::{.fragment}
**Calculations**:

- $\text{MAE} = \frac{5+5+5+8+5+3+3+10+3+50}{10} = \frac{97}{10} = 9.7$ m
- $\text{MSE} = \frac{25+25+25+64+25+9+9+100+9+2500}{10} = \frac{2791}{10} = 279.1$ m²
- $\text{RMSE} = \sqrt{279.1} = 16.7$ m

**Key insight**: One bad prediction (50 m error) dramatically inflates RMSE but has less effect on MAE. Ratio RMSE/MAE = 1.72 indicates presence of outliers.
:::

---

## MAE vs RMSE: Decision Guide

### Which Metric Should You Use?

:::{.callout-important}
## Safety-Critical Applications → Use RMSE

**When**: Aircraft performance limits, structural loads, V-speeds, obstacle clearance

**Why**: Large errors can be catastrophic. RMSE heavily penalizes outliers.

**Example**: Predicting maximum load factor — if model occasionally predicts 20% low, structure could fail.
:::

:::{.callout-note}
## Operational Planning → Consider MAE

**When**: Fuel planning, schedule estimates, maintenance intervals

**Why**: Occasional outliers are acceptable; focus on typical performance.

**Example**: Taxi-out time — usually 10-15 min, occasionally 45 min (traffic). MAE captures typical experience.
:::

---

## Detailed Metric Analysis: MAPE

### Mean Absolute Percentage Error

$$
\text{MAPE} = \frac{100\%}{n}\sum_{i=1}^n\left|\frac{y_i - \hat{y}_i}{y_i}\right|
$$

:::{.fragment}
**Properties**:

- **Scale-independent**: Expressed as percentage, comparable across different problems
- **Intuitive**: Non-technical stakeholders understand "5% error"
- **Asymmetric**: Penalizes under-predictions more than over-predictions
- **Undefined for $y_i = 0$**: Cannot divide by zero
:::

:::{.fragment}
**When to use**: Comparing models across different scales (fuel kg vs distance km), reporting to non-technical audiences, when relative accuracy matters more than absolute.
:::

---

## MAPE: Scale Independence Example

### Comparing Models Across Different Aircraft

**Model A** - Small business jet fuel prediction:

- Typical fuel burn: 1,200 kg
- RMSE = 50 kg → MAPE ≈ 4.2%

**Model B** - Heavy cargo aircraft fuel prediction:

- Typical fuel burn: 45,000 kg  
- RMSE = 1,500 kg → MAPE ≈ 3.3%

:::{.fragment}
**Conclusion**: Model B has 30× larger RMSE but lower MAPE. Both achieve similar **relative** accuracy for their respective applications. MAPE enables fair comparison across scales.
:::

---

## MAPE: Pitfalls to Avoid

:::{.callout-important}
### Pitfall 1: Asymmetry

MAPE penalizes under-predictions more than over-predictions of equal magnitude.

:::{.fragment}
**Example**: Predicting part cost of $100

- **Over-predict** by $50: Error = $\frac{|150-100|}{100} = 50\%$
- **Under-predict** by $50: Error = $\frac{|50-100|}{50} = 100\%$

Same absolute error, but under-prediction contributes **twice as much** to MAPE!
:::
:::

:::{.fragment}
:::{.callout-important}
### Pitfall 2: Division by Zero or Near-Zero

**Problem**: If true value $y_i \approx 0$, MAPE explodes

**Example**: Sideslip angle $\beta$ during wings-level flight

- True: $\beta = 0.5°$, Predicted: $\beta = 1.5°$ → MAPE = 200\%$ ❌ Misleading!

**Solution**: Use absolute metrics (MAE, RMSE) when values can be near zero.
:::
:::

---

## Summary: Choosing the Right Metric

### Decision Tree for Aerospace Applications

:::{.callout-tip}
## Step 1: What's Your Goal?

**Goal: Compare model performance on same dataset**

- Use **R²** or **Adj. R²** (intuitive variance explained)

**Goal: Interpretable error in engineering units**

- Use **RMSE** (if safety-critical, penalize outliers) or **MAE** (if robust to outliers)

**Goal: Compare across different problems/scales**

- Use **MAPE** (percentage, scale-independent)

**Goal: Model selection (avoid overfitting)**

- Use **Adj. R²** (penalizes complexity) or **Cross-validation RMSE/MAE**
:::

:::{.fragment}
:::{.callout-tip}
## Step 2: What's Your Application Domain?

- **Aircraft performance certification** → RMSE + Adj. R²
- **Operational fuel/time planning** → MAE + MAPE  
- **Research model comparison** → R², Adj. R², RMSE
- **Safety-critical systems** → RMSE (conservative)
:::
:::

:::{.fragment}
> Always use **multiple metrics** to give complete picture of model performance.
:::

---

## Comprehensive Error Metrics Table

### Quick Reference for Model Evaluation

| **Metric** | **Formula** | **Units** | **Interpretation** | **Advantages** | **Disadvantages** | **Aerospace Use Case** |
|------------|-------------|-----------|-------------------|----------------|-------------------|------------------------|
| **R²** | $1 - \frac{\text{RSS}}{\text{TSS}}$ | Unitless [0,1] | % variance explained | Intuitive, normalized | Always increases with features | Initial model assessment |
| **Adj. R²** | $1 - (1-R^2)\frac{n-1}{n-d-1}$ | Unitless | R² with complexity penalty | Prevents overfitting | Can be negative | Model selection/comparison |
| **MSE** | $\frac{1}{n}\sum(y_i-\hat{y}_i)^2$ | Squared units | Avg squared error | Easy to optimize | Squared units unintuitive | Theoretical analysis |
| **RMSE** | $\sqrt{\text{MSE}}$ | Same as $y$ | Typical prediction error | Interpretable units | Sensitive to outliers | **Primary metric (safety)** |
| **MAE** | $\frac{1}{n}\sum\|y_i-\hat{y}_i\|$ | Same as $y$ | Median absolute error | Robust to outliers | Harder to optimize | Operational planning |
| **MAPE** | $\frac{100}{n}\sum\frac{\|y_i-\hat{y}_i\|}{y_i}$ | Percentage | Avg % error | Scale-independent | Asymmetric, fails at $y=0$ | Comparing different scales |
| **Max Error** | $\max_i\|y_i-\hat{y}_i\|$ | Same as $y$ | Worst-case error | Identifies outliers | Single bad point | Safety margins |
| **CV Score** | Avg metric across folds | Various | Out-of-sample performance | Prevents overfitting | Computationally expensive | Model validation |

[**Recommended reporting**: R²/Adj. R² + RMSE + MAE (covers interpretability, safety, and robustness)]{.highlight}

---

## Aerospace Application: Drag Prediction

:::: {.columns}
::: {.column width="40%"}
### Problem Setup

**Goal**: Predict drag coefficient from wind tunnel data

**Features**:

- Angle of attack: $\alpha$ (deg)
- Mach number: $M$
- Reynolds number: $\text{Re}$

**Target**: Drag coefficient $C_D$
:::

::: {.column width="60%"}
### Feature Selection Strategy

**Small-scale problems** (limited data):

- Start with physics-based features from domain knowledge
- Include interaction terms guided by aerodynamic theory
- Manual selection based on hypothesis testing ($t$-tests, $p$-values)

**Large-scale problems** with strong physics:

- Physics-informed feature engineering (known functional forms)
- Add polynomial/interaction terms systematically
- Use regularization to handle redundancy

**Large-scale problems** without strong physics:

- Automated feature selection (forward/backward stepwise, Lasso)
- Cross-validation to assess feature importance
- Rely on data-driven patterns rather than domain knowledge
:::
::::

--- 

## Linear Model with Interaction Terms

$$
C_D = \beta_0 + \beta_1\alpha + \beta_2 M + \beta_3\text{Re} + \beta_4\alpha^2 + \beta_5 M^2 + \beta_6\alpha M + \epsilon
$$

**Rationale**:

- Parabolic drag polar: $C_D \propto \alpha^2$ (induced drag)
- Wave drag: $C_D \propto M^2$ (transonic effects)
- Compressibility: $\alpha M$ interaction

---

## Feature Engineering for Aerodynamics

### Polynomial Features

**Automated feature expansion** — Create new features from existing ones:

```python
from sklearn.preprocessing import PolynomialFeatures

# X is your original data matrix (n samples × 3 features)
# Shape: (n_samples, 3) where columns are [α, M, Re]

poly = PolynomialFeatures(degree=2, include_bias=True)
X_poly = poly.fit_transform(X)  # X_poly has shape (n_samples, 10)

# Transformation: [f1, f2, f3] → [1, f1, f2, f3, f1², f1×f2, f1×f3, f2², f2×f3, f3²]
# For our case:    [α, M, Re]  → [1, α,  M,  Re, α²,  α×M,   α×Re,  M²,  M×Re,  Re²]
```

**What this does**: Automatically generates all combinations of features up to degree 2

- **Bias term**: 1 (intercept, when `include_bias=True`)
- **Linear terms**: $\alpha, M, \text{Re}$ (original features)
- **Interaction terms**: $\alpha M, \alpha \text{Re}, M \text{Re}$ (captures coupling between variables)
- **Quadratic terms**: $\alpha^2, M^2, \text{Re}^2$ (captures nonlinear effects)

> For 3 input features, you get: 3 original + 3 interactions + 3 squares + 1 bias = **10 total features**

:::{.fragment}
**Important clarification**: This allows a **linear model** to fit **nonlinear relationships**

The model is still **linear in the coefficients**: $C_D = \beta_0 + \beta_1\alpha + \beta_2 M + \beta_3\alpha^2 + \cdots$

But it's **nonlinear in the input features**: $C_D$ depends on $\alpha^2$, not just $\alpha$

:::

-- 

## Use Domain Knowledge For Feature Selection

Rather than blindly creating all polynomials, use **aerodynamic theory** to guide feature selection:

1. **Dynamic pressure**: $q = \frac{1}{2}\rho V^2 \propto M^2$
   - Higher Mach → Higher dynamic pressure → Different flow physics
   - Create feature: $M^2$ to capture compressibility effects

2. **Lift-induced drag**: $C_{D_i} = \frac{C_L^2}{\pi e AR}$
   - Induced drag scales with square of lift coefficient
   - If predicting $C_D$ and have $C_L$ data, create feature: $C_L^2$

3. **Prandtl-Glauert correction**: $C_p = \frac{C_{p,0}}{\sqrt{1-M^2}}$ (subsonic compressibility)
   - Pressure coefficient correction for compressible flow
   - Create feature: $\frac{1}{\sqrt{1-M^2}}$ for subsonic Mach numbers


:::{.fragment}
**Key lesson**: Physics-informed feature engineering beats blind polynomial expansion

- Fewer features → Less overfitting
- Better interpretability → Understand what model learned
- Incorporates domain expertise → Model learns physics, not just correlations
:::

---

## Problem: Predicting Fatigue Life of Aircraft Components

**Given measurements**: Applied load $P$, component geometry (length $L$, cross-section area $A$, moment of inertia $I$), material properties (Young's modulus $E$, yield strength $\sigma_y$)

**Goal**: Predict cycles to failure

### Physics-Informed Features from Structural Theory

::: {.columns}
::: {.column}
:::{.fragment}
1. **Axial stress**: $\sigma = \frac{P}{A}$
   - Fundamental stress measure, directly related to failure
   - **Feature**: $\sigma$ or $\frac{P}{A}$

2. **Bending moment and stress**: $\sigma_{bend} = \frac{M \cdot c}{I}$
   - If component experiences bending, stress depends on moment $M$ and distance from neutral axis $c$
   - **Feature**: $\frac{M \cdot c}{I}$

3. **Euler buckling load**: $P_{cr} = \frac{\pi^2 E I}{(KL)^2}$
   - Critical load for column buckling (where $K$ is effective length factor)
   - **Feature**: Load ratio $\frac{P}{P_{cr}}$ indicates proximity to buckling instability
:::
:::

::: {.column}
:::{.fragment}
4. **Strain energy density**: $U = \frac{\sigma^2}{2E}$
   - Energy stored in material under load, correlates with damage accumulation
   - **Feature**: $\frac{\sigma^2}{2E}$

5. **Stress concentration factor**: $K_t = \frac{\sigma_{max}}{\sigma_{nominal}}$
   - Accounts for geometric discontinuities (holes, notches, fillets)
   - **Feature**: $K_t \cdot \sigma$ gives local peak stress where cracks initiate

:::
:::
:::

:::{.fragment}
> **Result**: Instead of raw measurements $[P, L, A, I, E]$, model uses physics-based features $[\sigma, \frac{P}{P_{cr}}, U, K_t\sigma]$ that directly relate to failure mechanisms.
:::
---

## Problem: Predicting Satellite Ground Track Position

**Given measurements**: Position vector $\vec{r}$, velocity vector $\vec{v}$, gravitational parameter $\mu = GM$

**Goal**: Predict future ground track latitude/longitude

### Physics-Informed Features from Orbital Theory

:::{.columns}
:::{.column}
:::{.fragment}
1. **Specific orbital energy**: $\mathcal{E} = \frac{v^2}{2} - \frac{\mu}{r}$
   - Determines orbit shape (ellipse, parabola, hyperbola)
   - Constant along orbit (conserved quantity)
   - **Feature**: $\mathcal{E}$ classifies orbit type

2. **Semi-major axis**: $a = -\frac{\mu}{2\mathcal{E}}$
   - Defines orbit size
   - Directly related to orbital period via Kepler's 3rd law: $T = 2\pi\sqrt{\frac{a^3}{\mu}}$
   - **Feature**: $a$ predicts when satellite returns to same location

3. **Specific angular momentum**: $\vec{h} = \vec{r} \times \vec{v}$, magnitude $h = |\vec{h}|$
   - Perpendicular to orbital plane, determines inclination
   - Constant in magnitude and direction (conserved quantity)
   - **Feature**: $h$ and components $(h_x, h_y, h_z)$ define orbital plane orientation
:::
:::

:::{.column}
:::{.fragment}
4. **Eccentricity**: $e = \sqrt{1 + \frac{2\mathcal{E}h^2}{\mu^2}}$
   - Describes orbit shape: $e=0$ (circular), $0<e<1$ (elliptical)
   - Determines apogee and perigee altitudes
   - **Feature**: $e$ predicts altitude variation

5. **Vis-viva equation** (from energy conservation): $v^2 = \mu\left(\frac{2}{r} - \frac{1}{a}\right)$
   - Latin for "living force" — relates orbital speed $v$ to position $r$ and orbit size $a$
   - Derived from conservation of energy: kinetic + potential = constant
   - At any point in orbit: faster when closer to Earth (smaller $r$), slower when farther
   - **Feature**: Given position, predict velocity magnitude (useful for ground speed calculations)

:::
:::
:::

:::{.fragment}
> **Result**: Instead of raw state vectors $[\vec{r}, \vec{v}]$ (6 numbers), model uses orbital elements $[\mathcal{E}, a, h, e, i, \Omega, \omega]$ that are physically meaningful and some are conserved (reduce dimensionality).
:::

---

## Scaling and Normalization

### Why Scale Features?

**Problem**: Features have different ranges

- $\alpha \in [0°, 20°]$
- $M \in [0.3, 0.9]$
- $\text{Re} \in [10^6, 10^7]$

:::{.fragment}
**Issues**:

1. Gradient descent: Features with large scales dominate
2. Regularization: Penalizes large-scale features unfairly
3. Numerical stability: Condition number of $\boldsymbol{X}^T\boldsymbol{X}$
:::

:::{.fragment}
### Standardization

$$
x_j^{\text{scaled}} = \frac{x_j - \mu_j}{\sigma_j}
$$

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```
:::

---

## Practical Implementation

### Scikit-learn Workflow

```python
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# 1. Load and split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. Create and train model
model = LinearRegression()
model.fit(X_train, y_train)

# 3. Make predictions
y_pred = model.predict(X_test)

# 4. Evaluate
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Coefficients: {model.coef_}")
print(f"Intercept: {model.intercept_}")
print(f"RMSE: {rmse:.4f}, R²: {r2:.4f}")
```

---

## Case Study: Boeing 737 Drag Model

### Dataset Description

- **Source**: Wind tunnel tests (hypothetical)
- **Samples**: 500 data points
- **Features**: $\alpha, M, \text{Re}$
- **Target**: $C_D$
- **Range**: Cruise conditions ($\alpha \in [0°, 10°]$, $M \in [0.7, 0.85]$)

:::{.fragment}
### Model Comparison

| Model | Features | R² | RMSE |
|-------|----------|-----|------|
| Simple | $\alpha, M$ | 0.85 | 0.0045 |
| Polynomial (deg=2) | 9 features | 0.94 | 0.0028 |
| + Reynolds | 10 features | 0.96 | 0.0022 |

:::

:::{.fragment}
**Insight**: Polynomial features capture drag polar curvature
:::

---

## Residual Analysis

### Diagnostic Plots

**1. Residuals vs. Fitted Values**

- Check for patterns (should be random)
- Funnel shape → heteroscedasticity

**2. Q-Q Plot**

- Check normality assumption
- Points should lie on diagonal

**3. Residuals vs. Features**

- Identify missing nonlinear terms
- Detect outliers

:::{.fragment}
```python
import matplotlib.pyplot as plt

residuals = y_test - y_pred
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Fitted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
```
:::

---

## Outliers and Influential Points

### Leverage and Influence

**Leverage**: How far is $\boldsymbol{x}_i$ from the center of the data?

$$
h_i = \boldsymbol{x}_i^T(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{x}_i
$$

:::{.fragment}
**Cook's Distance**: Combined effect of leverage and residual

$$
D_i = \frac{(y_i - \hat{y}_i)^2}{(d+1)\hat{\sigma}^2} \cdot \frac{h_i}{(1-h_i)^2}
$$

**Rule of thumb**: $D_i > 1$ suggests influential point
:::

:::{.fragment}
### Aerospace Context

**Outliers might be**:

- Sensor errors or calibration issues
- Unusual flight conditions (turbulence, icing)
- Model breakdown (post-stall, shock formation)
:::

---

## Limitations of Linear Regression

### When Linear Models Fail

**1. Nonlinear Relationships**

- Transonic drag rise: Not well-captured by polynomials
- Post-stall aerodynamics: Requires different model class

**2. Extrapolation Issues**

- Dangerous in aerospace (safety-critical)
- Model may predict physically impossible values

**3. Model Assumptions**

- Homoscedasticity rarely holds in real flight data
- Errors may be correlated (time-series flight data)

:::{.fragment}
### Solutions

- **Nonlinear models**: Neural networks (Weeks 7-9)
- **Tree-based methods**: Random forests, gradient boosting
- **Physics-informed ML**: Incorporate governing equations
:::

---

## Extensions and Variations

### Weighted Least Squares

**When**: Heteroscedastic errors (variance varies with $x$)

$$
\boldsymbol{\beta}^\ast = \arg\min_{\boldsymbol{\beta}} \sum_{i=1}^n w_i(y_i - \boldsymbol{x}_i^T\boldsymbol{\beta})^2
$$

**Solution**: $\boldsymbol{\beta} = (\boldsymbol{X}^T\boldsymbol{W}\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{W}\boldsymbol{y}$ where $\boldsymbol{W} = \text{diag}(w_1, \ldots, w_n)$

:::{.fragment}
### Generalized Least Squares

**When**: Correlated errors with known covariance $\boldsymbol{\Sigma}$

$$
\boldsymbol{\beta} = (\boldsymbol{X}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{y}
$$
:::

---

## Regularization Preview (Week 3)

### The Overfitting Problem

**High-dimensional features** ($d$ large):

- Perfect fit on training data
- Poor generalization to test data
- Coefficients become unstable

:::{.fragment}
### Ridge Regression (L2 Regularization)

$$
\boldsymbol{\beta}^{\ast,\text{ridge}} = \arg\min_{\boldsymbol{\beta}} \left\{\sum_{i=1}^n(y_i - \boldsymbol{x}_i^T\boldsymbol{\beta})^2 + \lambda\sum_{j=1}^d\beta_j^2\right\}
$$

**Solution**: $\boldsymbol{\beta}^{\ast,\text{ridge}} = (\boldsymbol{X}^T\boldsymbol{X} + \lambda\boldsymbol{I})^{-1}\boldsymbol{X}^T\boldsymbol{y}$

**Benefit**: Always invertible, even when $\boldsymbol{X}^T\boldsymbol{X}$ is singular
:::

---

## Flight Test Example: Fuel Flow Prediction

### Problem Statement

**Goal**: Predict fuel flow rate for mission planning

**Features**:

- Altitude: $h$ (ft)
- True airspeed: $V$ (kts)
- Aircraft weight: $W$ (lb)
- Temperature deviation: $\Delta T$ (°C)

**Target**: Fuel flow $\dot{m}_f$ (lb/hr)

:::{.fragment}
### Physical Model Basis

**Thrust specific fuel consumption (TSFC)**:
$$
\text{TSFC} = \frac{\dot{m}_f}{T}
$$

**Drag = Thrust** (cruise):
$$
T = D = \frac{1}{2}\rho V^2 S C_D
$$
:::

---

## Implementation: Fuel Flow Model

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline

# Load flight test data
df = pd.read_csv('flight_test_data.csv')
X = df[['altitude', 'velocity', 'weight', 'temp_dev']]
y = df['fuel_flow']

# Create pipeline with preprocessing and model
model = Pipeline([
    ('poly', PolynomialFeatures(degree=2, include_bias=True)),
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

# Train model
model.fit(X_train, y_train)

# Predict for new flight condition
new_condition = [[35000, 450, 150000, -10]]  # Alt, V, W, ΔT
predicted_fuel_flow = model.predict(new_condition)
print(f"Predicted fuel flow: {predicted_fuel_flow[0]:.1f} lb/hr")
```

---

## Gradient Descent from Scratch

### Manual Implementation

```python
def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):
    n, d = X.shape
    beta = np.zeros(d)  # Initialize parameters
    cost_history = []
    
    for iteration in range(n_iterations):
        # Compute predictions
        y_pred = X @ beta
        
        # Compute residuals
        residuals = y_pred - y
        
        # Compute gradient
        gradient = (2/n) * X.T @ residuals
        
        # Update parameters
        beta = beta - learning_rate * gradient
        
        # Track cost
        cost = np.mean(residuals**2)
        cost_history.append(cost)
        
        if iteration % 100 == 0:
            print(f"Iteration {iteration}: Cost = {cost:.6f}")
    
    return beta, cost_history
```

---

## Convergence Analysis

### Monitoring Convergence

```python
import matplotlib.pyplot as plt

# Run gradient descent
beta_gd, cost_history = gradient_descent(X_train, y_train)

# Compare with closed-form solution
beta_closed = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train

# Plot convergence
plt.figure(figsize=(10, 6))
plt.plot(cost_history)
plt.xlabel('Iteration')
plt.ylabel('Mean Squared Error')
plt.title('Gradient Descent Convergence')
plt.yscale('log')
plt.grid(True)
plt.show()

print(f"GD solution: {beta_gd}")
print(f"Closed-form solution: {beta_closed}")
print(f"Difference: {np.linalg.norm(beta_gd - beta_closed):.6e}")
```

---

## Multicollinearity Detection

### Variance Inflation Factor (VIF)

**Definition**: How much variance of $\beta_j$ is inflated due to correlation with other features

$$
\text{VIF}_j = \frac{1}{1 - R_j^2}
$$

where $R_j^2$ is from regressing $x_j$ on all other features

:::{.fragment}
**Rule of thumb**:

- VIF < 5: Low correlation
- VIF > 10: Problematic multicollinearity
:::

:::{.fragment}
```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_data = pd.DataFrame()
vif_data["Feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) 
                   for i in range(X.shape[1])]
print(vif_data)
```
:::

---

## Confidence and Prediction Intervals

### Two Types of Uncertainty

**Confidence Interval**: Uncertainty in mean response $E[y|\boldsymbol{x}]$

$$
\hat{y} \pm t_{\gamma/2, n-d-1} \cdot \hat{\sigma}\sqrt{\boldsymbol{x}^T(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{x}}
$$

:::{.fragment}
**Prediction Interval**: Uncertainty in individual prediction $y$

$$
\hat{y} \pm t_{\gamma/2, n-d-1} \cdot \hat{\sigma}\sqrt{1 + \boldsymbol{x}^T(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{x}}
$$

Note the extra "1" accounting for irreducible error
:::

:::{.fragment}
### Aerospace Application

**Critical for**:

- Flight envelope certification
- Fuel reserve calculations
- Performance guarantees
:::

---

## Practical Tips for Aerospace ML

### Data Quality Matters

1. **Sensor calibration**: Check for drift, bias
2. **Data fusion**: Combine multiple sources (INS, GPS, pitot-static)
3. **Outlier handling**: Physics-based filtering (e.g., impossible speeds)
4. **Missing data**: Interpolation vs. imputation

:::{.fragment}
### Feature Selection Strategy

1. Start with **physical model** (drag polar, Breguet range)
2. Add **polynomial terms** based on theory
3. Use **domain expertise** to limit feature space
4. **Cross-validate** to prevent overfitting
:::

:::{.fragment}
### Model Validation

- **Train-test split**: 80-20 or 70-30
- **K-fold CV**: For limited data
- **Holdout by flight**: Test on different aircraft/conditions
- **Physics checks**: Verify positive drag, reasonable trends
:::

---

## Software Ecosystem

### Essential Libraries

```python
# Data manipulation
import numpy as np
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Machine learning
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score

# Statistical analysis
import scipy.stats as stats
import statsmodels.api as sm

# Aerospace-specific (optional)
from ambiance import Atmosphere  # ISA atmosphere model
```

---

## Homework 1 Preview

### Assignment Overview

**Task**: Build linear regression model for aircraft drag prediction

1. **Data exploration**: Load and visualize wind tunnel data
2. **Feature engineering**: Create polynomial and interaction terms
3. **Model training**: Implement with scikit-learn and from scratch
4. **Evaluation**: Cross-validation, residual analysis
5. **Interpretation**: Relate coefficients to aerodynamics

:::{.fragment}
### Deliverables

- Jupyter notebook with analysis
- Written report (max 5 pages)
- Trained model file (`.pkl`)
- Presentation slides (5 min)

**Due**: Next week, before class
:::

---

## Key Takeaways

### Mathematical Foundations

1. Linear regression minimizes squared error: $\min \|\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\beta}^\ast\|^2$
2. Closed-form solution: $\boldsymbol{\beta}^\ast = (\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}$
3. Gradient descent for large-scale problems
4. Statistical properties: BLUE under Gauss-Markov

:::{.fragment}
### Practical Implementation

1. Feature scaling essential for numerical stability
2. Cross-validation for generalization assessment
3. Residual analysis for model diagnostics
4. Domain knowledge guides feature engineering
:::

:::{.fragment}
### Aerospace Applications

- Drag prediction, fuel flow modeling, performance estimation
- Physics-informed features improve accuracy
- Always validate against known aerodynamic principles
:::

---

## Next Week: Model Evaluation & Regularization

### Preview of Week 3

**Topics**:

1. **Bias-variance tradeoff**: Understanding generalization
2. **Ridge regression**: L2 regularization for stability
3. **Lasso regression**: L1 regularization for sparsity
4. **Elastic net**: Combined L1 + L2
5. **Cross-validation**: Hyperparameter tuning

**Aerospace focus**: Preventing overfitting in high-dimensional aerodynamic models

<!-- ---

## Additional Practice Problems

### Problem 1: Lift Coefficient Prediction
Given wind tunnel data for a wing section, predict $C_L$ from $\alpha$ and $M$.

### Problem 2: Range Estimation
Use Breguet range equation as basis for linear regression model.

### Problem 3: Gradient Descent Tuning
Implement adaptive learning rate and compare convergence.

### Problem 4: Feature Selection
Use statistical tests to identify significant features in drag model.

### Problem 5: Multi-Aircraft Model
Build single model that works for multiple aircraft types using categorical variables.

--- -->

